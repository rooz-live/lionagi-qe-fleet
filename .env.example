# LionAGI QE Fleet Configuration

# Required: OpenAI API Key
OPENAI_API_KEY=your_openai_api_key_here

# Optional: Anthropic API Key (for Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Optional: Ollama for local models
# OLLAMA_HOST=http://localhost:11434

# Fleet Configuration
ENABLE_ROUTING=true
ENABLE_LEARNING=false

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Storage Mode Configuration
# Automatic backend selection based on environment mode
# Valid values: development, testing, production
AQE_STORAGE_MODE=development

# Alternative environment variable names (checked in order):
# - AQE_STORAGE_MODE (explicit override)
# - ENVIRONMENT (common in Docker/cloud platforms)
# - NODE_ENV (Node.js convention)
# If none are set, defaults to 'development'

# Production Mode Configuration (required when AQE_STORAGE_MODE=production)
# DATABASE_URL=postgresql://user:password@localhost:5432/lionagi_qe_learning

# Database Connection Pool (production mode only)
DB_POOL_SIZE=5                # Minimum connections in pool
DB_POOL_MAX_OVERFLOW=20       # Maximum additional connections beyond pool size
DB_CONNECTION_TIMEOUT=30      # Connection timeout in seconds
DB_POOL_RECYCLE=3600          # Connection recycle time (seconds) - prevents stale connections

# Memory Configuration
MEMORY_TTL_DEFAULT=86400  # 24 hours in seconds
MEMORY_PARTITION_DEFAULT=default

# Cost Optimization
ROUTER_DEFAULT_MODEL=gpt-4o-mini
ROUTER_ANALYZE_COMPLEXITY=true

# Testing
TEST_FRAMEWORK=pytest
TEST_PARALLEL=true
TEST_COVERAGE_THRESHOLD=80
